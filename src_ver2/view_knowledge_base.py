#!/usr/bin/env python3
"""
Script ƒë∆°n gi·∫£n ƒë·ªÉ xem d·ªØ li·ªáu trong knowledge base test.
Hi·ªÉn th·ªã th√¥ng tin v·ªÅ documents ƒë√£ ƒë∆∞·ª£c index trong LanceDB.
"""

import os
import sys
from pathlib import Path

import lancedb
import pandas as pd
from langchain_ollama import OllamaEmbeddings
from langchain_community.vectorstores import LanceDB


def main():
    """Xem d·ªØ li·ªáu trong knowledge base test."""
    
    # ƒê∆∞·ªùng d·∫´n ƒë·∫øn knowledge base
    knowledge_base_path = Path("appdata/knowledge_base_test")
    lancedb_path = knowledge_base_path / "lancedb"
    table_name = "documents"
    
    print("üîç Knowledge Base Viewer")
    print("=" * 50)
    print(f"üìÇ Knowledge Base: {knowledge_base_path}")
    print(f"üóÑÔ∏è LanceDB Path: {lancedb_path}")
    print(f"üìä Table Name: {table_name}")
    print()
    
    # Ki·ªÉm tra xem knowledge base c√≥ t·ªìn t·∫°i kh√¥ng
    if not knowledge_base_path.exists():
        print(f"‚ùå Knowledge base kh√¥ng t·ªìn t·∫°i: {knowledge_base_path}")
        return
    
    if not lancedb_path.exists():
        print(f"‚ùå LanceDB kh√¥ng t·ªìn t·∫°i: {lancedb_path}")
        return
    
    try:
        # K·∫øt n·ªëi ƒë·∫øn LanceDB
        print("üîå ƒêang k·∫øt n·ªëi ƒë·∫øn LanceDB...")
        db = lancedb.connect(str(lancedb_path))
        
        # Li·ªát k√™ c√°c table c√≥ s·∫µn
        tables = db.table_names()
        print(f"üìã Tables c√≥ s·∫µn: {tables}")
        
        if table_name not in tables:
            print(f"‚ùå Table '{table_name}' kh√¥ng t·ªìn t·∫°i!")
            return
        
        # M·ªü table
        table = db.open_table(table_name)
        
        # Th·ªëng k√™ c∆° b·∫£n
        total_rows = table.count_rows()
        print(f"üìä T·ªïng s·ªë documents: {total_rows}")
        
        if total_rows == 0:
            print("üì≠ Kh√¥ng c√≥ document n√†o trong table!")
            return
        
        print()
        print("=" * 50)
        print("üìà TH·ªêNG K√ä D·ªÆ LI·ªÜU")
        print("=" * 50)
        
        # L·∫•y to√†n b·ªô d·ªØ li·ªáu ƒë·ªÉ ph√¢n t√≠ch
        df = table.to_pandas()
        
        # Hi·ªÉn th·ªã th√¥ng tin c·ªôt
        print(f"üìã S·ªë c·ªôt: {len(df.columns)}")
        print(f"üìù T√™n c√°c c·ªôt: {list(df.columns)}")
        print()
        
        # Th·ªëng k√™ metadata
        if 'file_name' in df.columns:
            unique_files = df['file_name'].nunique()
            print(f"üìÑ S·ªë file PDF unique: {unique_files}")
            print(f"üìÉ Danh s√°ch files:")
            for file_name in df['file_name'].unique():
                count = len(df[df['file_name'] == file_name])
                print(f"   - {file_name}: {count} chunks")
        
        if 'chunk_length' in df.columns:
            avg_length = df['chunk_length'].mean()
            min_length = df['chunk_length'].min()
            max_length = df['chunk_length'].max()
            print(f"üìè ƒê·ªô d√†i chunk trung b√¨nh: {avg_length:.0f} k√Ω t·ª±")
            print(f"üìê ƒê·ªô d√†i chunk min/max: {min_length}/{max_length} k√Ω t·ª±")
        
        print()
        print("=" * 50)
        print("üìÑ M·∫™U DOCUMENTS")
        print("=" * 50)
        
        # Hi·ªÉn th·ªã 3 document ƒë·∫ßu ti√™n
        sample_limit = min(3, total_rows)
        
        for i in range(sample_limit):
            row = df.iloc[i]
            print(f"\nüìù Document {i+1}:")
            print(f"   üîñ File: {row.get('file_name', 'N/A')}")
            print(f"   üìÑ Chunk: {row.get('chunk_index', 'N/A')}/{row.get('total_chunks', 'N/A')}")
            print(f"   üìè ƒê·ªô d√†i: {row.get('chunk_length', 'N/A')} k√Ω t·ª±")
            print(f"   üìÉ Preview content:")
            
            content = row.get('text', '') or row.get('page_content', '')
            preview = content[:200] + "..." if len(content) > 200 else content
            print(f"      {preview}")
        
        print()
        print("=" * 50)
        print("üîç SEARCH TEST")
        print("=" * 50)
        
        # Test search function v·ªõi embedding
        try:
            print("ü§ñ ƒêang kh·ªüi t·∫°o embedding model...")
            embeddings = OllamaEmbeddings(model="nomic-embed-text:latest")
            
            # T·∫°o vectorstore
            vectorstore = LanceDB(
                uri=str(lancedb_path),
                embedding=embeddings,
                table_name=table_name,
                mode="read"
            )
            
            # Test search
            test_query = "sai s·ªë"
            print(f"üîç Test search v·ªõi query: '{test_query}'")
            
            results = vectorstore.similarity_search(test_query, k=2)
            
            print(f"‚úÖ T√¨m th·∫•y {len(results)} k·∫øt qu·∫£:")
            for idx, doc in enumerate(results, 1):
                preview = doc.page_content[:150] + "..." if len(doc.page_content) > 150 else doc.page_content
                print(f"   {idx}. {preview}")
                print(f"      üìÑ File: {doc.metadata.get('file_name', 'N/A')}")
                print()
        
        except Exception as e:
            print(f"‚ö†Ô∏è Kh√¥ng th·ªÉ test search: {e}")
        
        print("=" * 50)
        print("‚úÖ Ho√†n th√†nh xem knowledge base!")
        
    except Exception as e:
        print(f"‚ùå L·ªói khi truy c·∫≠p LanceDB: {e}")
        return


if __name__ == "__main__":
    main() 