#!/usr/bin/env python3
"""
Script Ä‘Æ¡n giáº£n Ä‘á»ƒ xem dá»¯ liá»‡u trong knowledge base test.
Hiá»ƒn thá»‹ thÃ´ng tin vá» documents Ä‘Ã£ Ä‘Æ°á»£c index trong LanceDB.
"""

import os
import sys
from pathlib import Path

import lancedb
import pandas as pd
from langchain_ollama import OllamaEmbeddings
from langchain_community.vectorstores import LanceDB


def main():
    """Xem dá»¯ liá»‡u trong knowledge base test."""
    
    # ÄÆ°á»ng dáº«n Ä‘áº¿n knowledge base
    knowledge_base_path = Path("appdata/knowledge_base_test")
    lancedb_path = knowledge_base_path / "lancedb"
    table_name = "documents"
    
    print("ğŸ” Knowledge Base Viewer")
    print("=" * 50)
    print(f"ğŸ“‚ Knowledge Base: {knowledge_base_path}")
    print(f"ğŸ—„ï¸ LanceDB Path: {lancedb_path}")
    print(f"ğŸ“Š Table Name: {table_name}")
    print()
    
    # Kiá»ƒm tra xem knowledge base cÃ³ tá»“n táº¡i khÃ´ng
    if not knowledge_base_path.exists():
        print(f"âŒ Knowledge base khÃ´ng tá»“n táº¡i: {knowledge_base_path}")
        return
    
    if not lancedb_path.exists():
        print(f"âŒ LanceDB khÃ´ng tá»“n táº¡i: {lancedb_path}")
        return
    
    try:
        # Káº¿t ná»‘i Ä‘áº¿n LanceDB
        print("ğŸ”Œ Äang káº¿t ná»‘i Ä‘áº¿n LanceDB...")
        db = lancedb.connect(str(lancedb_path))
        
        # Liá»‡t kÃª cÃ¡c table cÃ³ sáºµn
        tables = db.table_names()
        print(f"ğŸ“‹ Tables cÃ³ sáºµn: {tables}")
        
        if table_name not in tables:
            print(f"âŒ Table '{table_name}' khÃ´ng tá»“n táº¡i!")
            return
        
        # Má»Ÿ table
        table = db.open_table(table_name)
        
        # Thá»‘ng kÃª cÆ¡ báº£n
        total_rows = table.count_rows()
        print(f"ğŸ“Š Tá»•ng sá»‘ documents: {total_rows}")
        
        if total_rows == 0:
            print("ğŸ“­ KhÃ´ng cÃ³ document nÃ o trong table!")
            return
        
        print()
        print("=" * 50)
        print("ğŸ“ˆ THá»NG KÃŠ Dá»® LIá»†U")
        print("=" * 50)
        
        # Láº¥y toÃ n bá»™ dá»¯ liá»‡u Ä‘á»ƒ phÃ¢n tÃ­ch
        df = table.to_pandas()
        
        # Hiá»ƒn thá»‹ thÃ´ng tin cá»™t
        print(f"ğŸ“‹ Sá»‘ cá»™t: {len(df.columns)}")
        print(f"ğŸ“ TÃªn cÃ¡c cá»™t: {list(df.columns)}")
        print()
        
        # Thá»‘ng kÃª metadata
        if 'file_name' in df.columns:
            unique_files = df['file_name'].nunique()
            print(f"ğŸ“„ Sá»‘ file PDF unique: {unique_files}")
            print(f"ğŸ“ƒ Danh sÃ¡ch files:")
            for file_name in df['file_name'].unique():
                count = len(df[df['file_name'] == file_name])
                print(f"   - {file_name}: {count} chunks")
        
        if 'chunk_length' in df.columns:
            avg_length = df['chunk_length'].mean()
            min_length = df['chunk_length'].min()
            max_length = df['chunk_length'].max()
            print(f"ğŸ“ Äá»™ dÃ i chunk trung bÃ¬nh: {avg_length:.0f} kÃ½ tá»±")
            print(f"ğŸ“ Äá»™ dÃ i chunk min/max: {min_length}/{max_length} kÃ½ tá»±")
        
        print()
        print("=" * 50)
        print("ğŸ“„ MáºªU DOCUMENTS")
        print("=" * 50)
        
        # Hiá»ƒn thá»‹ 3 document Ä‘áº§u tiÃªn
        sample_limit = min(3, total_rows)
        
        for i in range(sample_limit):
            row = df.iloc[i]
            print(f"\nğŸ“ Document {i+1}:")
            print(f"   ğŸ”– File: {row.get('file_name', 'N/A')}")
            print(f"   ğŸ“„ Chunk: {row.get('chunk_index', 'N/A')}/{row.get('total_chunks', 'N/A')}")
            print(f"   ğŸ“ Äá»™ dÃ i: {row.get('chunk_length', 'N/A')} kÃ½ tá»±")
            print(f"   ğŸ“ƒ Preview content:")
            
            content = row.get('text', '') or row.get('page_content', '')
            preview = content[:200] + "..." if len(content) > 200 else content
            print(f"      {preview}")
        
        print()
        print("=" * 50)
        print("ğŸ” SEARCH TEST")
        print("=" * 50)
        
        # Test search function vá»›i embedding
        try:
            print("ğŸ¤– Äang khá»Ÿi táº¡o embedding model...")
            embeddings = OllamaEmbeddings(model="nomic-embed-text:latest")
            
            # Táº¡o vectorstore
            vectorstore = LanceDB(
                uri=str(lancedb_path),
                embedding=embeddings,
                table_name=table_name,
                mode="read"
            )
            
            # Test search
            test_query = "user calibration"
            print(f"ğŸ” Test search vá»›i query: '{test_query}'")
            
            results = vectorstore.similarity_search(test_query, k=10)
            
            print(f"âœ… TÃ¬m tháº¥y {len(results)} káº¿t quáº£:")
            for idx, doc in enumerate(results, 1):
                preview = doc.page_content[:150] + "..." if len(doc.page_content) > 150 else doc.page_content
                print(f"   {idx}. {preview}")
                print(f"      ğŸ“„ File: {doc.metadata.get('file_name', 'N/A')}")
                print(f"      ğŸ“„ Page: {doc.metadata.get('page_number', 'N/A')}")
                print()
        
        except Exception as e:
            print(f"âš ï¸ KhÃ´ng thá»ƒ test search: {e}")
        
        print("=" * 50)
        print("âœ… HoÃ n thÃ nh xem knowledge base!")
        
    except Exception as e:
        print(f"âŒ Lá»—i khi truy cáº­p LanceDB: {e}")
        return


if __name__ == "__main__":
    main() 