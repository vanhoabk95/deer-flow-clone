# ğŸ“š HÆ°á»›ng dáº«n sá»­ dá»¥ng Local Knowledge Base

HÆ°á»›ng dáº«n nÃ y sáº½ giÃºp báº¡n thiáº¿t láº­p vÃ  sá»­ dá»¥ng há»‡ thá»‘ng Knowledge Base local thay tháº¿ RAGFlow trong DeerFlow.

## ğŸ¯ Tá»•ng quan

DeerFlow Ä‘Ã£ Ä‘Æ°á»£c cáº­p nháº­t Ä‘á»ƒ há»— trá»£ Knowledge Base local vá»›i cÃ¡c tÃ­nh nÄƒng:

- âœ… **Local Storage**: LÆ°u trá»¯ dá»¯ liá»‡u táº¡i thÆ° má»¥c `appdata/` 
- âœ… **LanceDB**: Vector database serverless local
- âœ… **Ollama Embeddings**: Sá»­ dá»¥ng embedding models local
- âœ… **Web UI**: Quáº£n lÃ½ knowledge bases qua giao diá»‡n web
- âœ… **Chat Integration**: Mention knowledge bases trong chat vá»›i `@` syntax
- âœ… **Retrieval**: TÃ¬m kiáº¿m semantic trong knowledge bases

## ğŸš€ CÃ i Ä‘áº·t nhanh

### 1. Cháº¡y setup script

```bash
# Setup mÃ´i trÆ°á»ng vÃ  dependencies
uv run python setup_local_kb.py
```

### 2. CÃ i Ä‘áº·t Ollama (náº¿u chÆ°a cÃ³)

```bash
# macOS/Linux
curl -fsSL https://ollama.ai/install.sh | sh

# Windows: Download tá»« https://ollama.ai/download

# Start Ollama service
ollama serve

# Pull embedding model
ollama pull nomic-embed-text
```

### 3. Test há»‡ thá»‘ng

```bash
# Test local knowledge base
uv run python test_local_kb.py
```

### 4. Khá»Ÿi Ä‘á»™ng servers

```bash
# Backend
uv run python server.py

# Frontend (terminal má»›i)
cd web
pnpm dev
```

## ğŸ“ Cáº¥u trÃºc thÆ° má»¥c

```
appdata/
â”œâ”€â”€ knowledge_base_test/           # Knowledge base máº«u
â”‚   â”œâ”€â”€ metadata.json             # Metadata cá»§a KB
â”‚   â”œâ”€â”€ documents/                # File documents gá»‘c
â”‚   â”‚   â”œâ”€â”€ file1.pdf
â”‚   â”‚   â””â”€â”€ file2.pdf
â”‚   â”œâ”€â”€ markdown/                 # Markdown converted files
â”‚   â”‚   â”œâ”€â”€ file1.md
â”‚   â”‚   â””â”€â”€ file2.md
â”‚   â””â”€â”€ lancedb/                  # Vector database
â”‚       â””â”€â”€ documents.lance/
â””â”€â”€ demo_knowledge_base/          # KB khÃ¡c
    â”œâ”€â”€ metadata.json
    â”œâ”€â”€ documents/
    â”œâ”€â”€ markdown/
    â””â”€â”€ lancedb/
```

## âš™ï¸ Cáº¥u hÃ¬nh

### Environment Variables (.env)

```bash
# RAG Provider
RAG_PROVIDER=local_kb

# Local Knowledge Base Settings
LOCAL_KB_MAX_RESULTS=10
EMBEDDING_MODEL=nomic-embed-text

# Search API
SEARCH_API=duckduckgo

# LLM API Keys
OPENAI_API_KEY=your_key_here
ANTHROPIC_API_KEY=your_key_here
```

### Config file (conf.yaml)

```yaml
llm:
  provider: "ollama"  # hoáº·c openai, anthropic
  model: "llama3.2"   # model cho reasoning
  
agents:
  researcher:
    llm_type: "smart"  # sá»­ dá»¥ng LLM máº¡nh cho research
  coder:
    llm_type: "fast"   # sá»­ dá»¥ng LLM nháº¹ cho code
```

## ğŸŒ Sá»­ dá»¥ng Web UI

### 1. Quáº£n lÃ½ Knowledge Bases

Truy cáº­p: `http://localhost:3000/knowledge-base`

- **Táº¡o KB má»›i**: Click "Create Knowledge Base"
- **Upload tÃ i liá»‡u**: Click "Upload Documents" trong KB card
- **Xem documents**: Click "View Documents" 
- **Edit/Delete**: Sá»­ dá»¥ng cÃ¡c button trÃªn KB card

### 2. Chat vá»›i Knowledge Base

Truy cáº­p: `http://localhost:3000/chat`

#### Mention Knowledge Base:
```
@Knowledge Base Test tell me about statistics
```

#### URI Format:
- `kb://knowledge_base_test` - ToÃ n bá»™ knowledge base
- `kb://demo_knowledge_base` - KB khÃ¡c

## ğŸ” CÃ¡ch hoáº¡t Ä‘á»™ng

### 1. Chat Flow

```mermaid
graph TD
    A[User mentions @KB] --> B[Frontend gá»­i resources]
    B --> C[Researcher Agent]
    C --> D[local_search_tool]
    D --> E[LocalKnowledgeBaseProvider]
    E --> F[LanceDB Query]
    F --> G[Return relevant chunks]
    G --> H[Researcher synthesizes]
    H --> I[Final report]
```

### 2. Retrieval Process

1. **User Input**: `@Knowledge Base Test explain DMAIC`
2. **Resource Detection**: Frontend detect `@` vÃ  convert thÃ nh `kb://knowledge_base_test`
3. **Tool Selection**: Researcher agent prioritize `local_search_tool`
4. **Embedding Search**: Query Ä‘Æ°á»£c embed vÃ  tÃ¬m kiáº¿m trong LanceDB
5. **Result Synthesis**: Káº¿t quáº£ Ä‘Æ°á»£c tá»•ng há»£p vá»›i web search

## ğŸ› ï¸ API Endpoints

### Knowledge Base Management

```typescript
GET    /api/knowledge-bases              // List all KBs
POST   /api/knowledge-bases              // Create new KB
PUT    /api/knowledge-bases/{id}         // Update KB
DELETE /api/knowledge-bases/{id}         // Delete KB
GET    /api/knowledge-bases/search       // Search KBs
```

### RAG Resources

```typescript
GET    /api/rag/resources?query=test     // List resources for mention
GET    /api/rag/config                   // Get RAG config
```

### Chat Integration

```typescript
POST   /api/chat/stream                  // Stream chat vá»›i resources
```

## ğŸ”§ Troubleshooting

### 1. Ollama Issues

```bash
# Check Ollama status
curl http://localhost:11434/api/tags

# Pull embedding model
ollama pull nomic-embed-text

# Check models
ollama list
```

### 2. LanceDB Issues

```bash
# Check if LanceDB directory exists
ls -la appdata/knowledge_base_test/lancedb/

# Re-index if needed (future feature)
# uv run python reindex_kb.py knowledge_base_test
```

### 3. Empty Search Results

- âœ… Verify knowledge base cÃ³ documents
- âœ… Check Ollama embedding model 
- âœ… Verify LanceDB data exists
- âœ… Try simpler queries

### 4. Frontend Issues

```bash
# Check API connection
curl http://localhost:8000/api/knowledge-bases

# Restart servers
# Backend: Ctrl+C, then uv run python server.py  
# Frontend: Ctrl+C, then pnpm dev
```

## ğŸš€ CÃ¡c tÃ­nh nÄƒng sáº½ cÃ³

### ÄÃ£ hoÃ n thÃ nh âœ…
- Local knowledge base provider
- Web UI cho management
- Chat integration vá»›i mention
- LanceDB vector search
- Ollama embeddings

### Káº¿ hoáº¡ch ğŸ“‹
- Document upload vÃ  auto-indexing
- Document deletion
- Knowledge base update/delete
- Advanced search filters
- Multiple embedding models
- Batch document processing

## ğŸ’¡ Tips & Best Practices

### 1. Embedding Model Selection
```bash
# Lightweight, fast
ollama pull nomic-embed-text

# Better quality, slower  
ollama pull mxbai-embed-large
```

### 2. Query Optimization
- Sá»­ dá»¥ng keywords cá»¥ thá»ƒ thay vÃ¬ cÃ¢u há»i dÃ i
- Thá»­ nhiá»u cÃ¡ch diá»…n Ä‘áº¡t náº¿u khÃ´ng cÃ³ káº¿t quáº£
- Combine vá»›i web search cho thÃ´ng tin má»›i nháº¥t

### 3. Knowledge Base Organization
- Táº¡o KB riÃªng cho tá»«ng chá»§ Ä‘á»
- Sá»­ dá»¥ng tÃªn vÃ  mÃ´ táº£ rÃµ rÃ ng
- Upload documents liÃªn quan cÃ¹ng nhau

### 4. Performance
- LanceDB query tá»‘t vá»›i <= 1000 documents
- Sá»­ dá»¥ng `LOCAL_KB_MAX_RESULTS` Ä‘á»ƒ limit káº¿t quáº£
- Embedding cached sau láº§n Ä‘áº§u query

## ğŸ¤ Há»— trá»£

Náº¿u gáº·p váº¥n Ä‘á»:

1. Cháº¡y test script: `uv run python test_local_kb.py`
2. Check logs trong terminal backend
3. Verify cáº¥u hÃ¬nh trong `.env` file
4. Ensure Ollama Ä‘ang cháº¡y
5. Restart cáº£ backend vÃ  frontend

---

ğŸ‰ **ChÃºc báº¡n sá»­ dá»¥ng DeerFlow Local Knowledge Base hiá»‡u quáº£!** 