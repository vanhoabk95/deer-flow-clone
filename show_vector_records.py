#!/usr/bin/env python3
"""
Script ƒë·ªÉ hi·ªÉn th·ªã t·∫•t c·∫£ c√°c b·∫£n ghi trong vector database
"""

import os
import sys
from pathlib import Path

def show_all_vector_records():
    """Hi·ªÉn th·ªã t·∫•t c·∫£ c√°c b·∫£n ghi trong vector database"""
    print("üîç Vector Database Records Viewer")
    print("=" * 50)
    
    try:
        import lancedb
        print("‚úÖ LanceDB import OK")
        
        # Ki·ªÉm tra th∆∞ m·ª•c appdata
        appdata_path = os.path.join(os.getcwd(), "appdata")
        print(f"üìÅ Appdata path: {appdata_path}")
        
        if not os.path.exists(appdata_path):
            print("‚ùå Appdata directory not found")
            return
        
        # Li·ªát k√™ c√°c th∆∞ m·ª•c trong appdata
        kb_dirs = [d for d in os.listdir(appdata_path) 
                  if os.path.isdir(os.path.join(appdata_path, d))]
        
        print(f"üìã Found knowledge base directories: {kb_dirs}")
        
        if not kb_dirs:
            print("‚ùå No knowledge base directories found")
            return
        
        # X·ª≠ l√Ω t·ª´ng knowledge base
        for kb_id in kb_dirs:
            print(f"\n{'='*60}")
            print(f"üéØ KNOWLEDGE BASE: {kb_id}")
            print(f"{'='*60}")
            
            kb_path = os.path.join(appdata_path, kb_id)
            lancedb_path = os.path.join(kb_path, "lancedb")
            
            print(f"üìÅ KB path: {kb_path}")
            print(f"üìÅ LanceDB path: {lancedb_path}")
            
            if not os.path.exists(lancedb_path):
                print("‚ùå LanceDB directory not found")
                continue
            
            # K·∫øt n·ªëi ƒë·∫øn LanceDB
            db = lancedb.connect(lancedb_path)
            tables = db.table_names()
            print(f"üìä Tables: {tables}")
            
            if "documents" not in tables:
                print("‚ùå 'documents' table not found")
                continue
            
            # M·ªü table documents
            table = db.open_table("documents")
            
            # L·∫•y schema
            schema = table.schema
            print(f"\nüìã Schema:")
            for field in schema:
                print(f"  - {field.name}: {field.type}")
            
            # ƒê·∫øm records
            count = table.count_rows()
            print(f"\nüìä Total records: {count}")
            
            if count == 0:
                print("‚ÑπÔ∏è  No records found")
                continue
            
            # L·∫•y t·∫•t c·∫£ records
            df = table.to_pandas()
            
            # Nh√≥m theo file
            files = {}
            for _, row in df.iterrows():
                metadata = row.get('metadata', {})
                file_name = metadata.get('file_name', 'Unknown')
                
                if file_name not in files:
                    files[file_name] = []
                files[file_name].append(row)
            
            # Hi·ªÉn th·ªã t·ª´ng file
            for file_name, records in files.items():
                print(f"\nüìÑ FILE: {file_name}")
                print(f"   Chunks: {len(records)}")
                print(f"   {'-'*40}")
                
                # S·∫Øp x·∫øp theo chunk_index
                records.sort(key=lambda x: x.get('metadata', {}).get('chunk_index', 0))
                
                for i, record in enumerate(records):
                    metadata = record.get('metadata', {})
                    chunk_index = metadata.get('chunk_index', 'N/A')
                    total_chunks = metadata.get('total_chunks', 'N/A')
                    chunk_length = metadata.get('chunk_length', 'N/A')
                    
                    print(f"\n   Chunk {chunk_index}/{total_chunks} (Length: {chunk_length} chars):")
                    
                    # Hi·ªÉn th·ªã text
                    text = record.get('text', '')
                    if text:
                        # Lo·∫°i b·ªè c√°c k√Ω t·ª± xu·ªëng d√≤ng v√† kho·∫£ng tr·∫Øng th·ª´a
                        cleaned_text = ' '.join(text.split())
                        if len(cleaned_text) > 200:
                            preview = cleaned_text[:200] + "..."
                        else:
                            preview = cleaned_text
                        print(f"   Content: {preview}")
                    
                    # Hi·ªÉn th·ªã ID
                    record_id = record.get('id', 'N/A')
                    print(f"   ID: {record_id}")
            
            # Test search v·ªõi m·ªôt s·ªë t·ª´ kh√≥a
            print(f"\nüîç Search Test Results:")
            test_queries = ["test", "ph√¢n ph·ªëi", "chu·∫©n", "data"]
            
            for query in test_queries:
                try:
                    # T·∫°o query vector ƒë∆°n gi·∫£n (zeros)
                    import numpy as np
                    query_vector = np.zeros(768)
                    
                    # Th·ª±c hi·ªán search
                    results = table.search(query_vector).limit(2).to_pandas()
                    
                    if not results.empty:
                        print(f"   Query '{query}': Found {len(results)} results")
                        for idx, row in results.head(1).iterrows():
                            metadata = row.get('metadata', {})
                            file_name = metadata.get('file_name', 'N/A')
                            score = row.get('_distance', 'N/A')
                            print(f"     - File: {file_name}, Score: {score:.4f}")
                    else:
                        print(f"   Query '{query}': No results")
                        
                except Exception as e:
                    print(f"   Query '{query}': Error - {e}")
        
        return True
        
    except Exception as e:
        print(f"‚ùå Error: {e}")
        import traceback
        traceback.print_exc()
        return False

def show_specific_file_records(kb_id: str, file_name: str):
    """Hi·ªÉn th·ªã records c·ªßa m·ªôt file c·ª• th·ªÉ"""
    print(f"\nüîç Records for file: {file_name} in KB: {kb_id}")
    print("=" * 60)
    
    try:
        import lancedb
        
        appdata_path = os.path.join(os.getcwd(), "appdata")
        kb_path = os.path.join(appdata_path, kb_id)
        lancedb_path = os.path.join(kb_path, "lancedb")
        
        if not os.path.exists(lancedb_path):
            print("‚ùå LanceDB directory not found")
            return
        
        # K·∫øt n·ªëi ƒë·∫øn LanceDB
        db = lancedb.connect(lancedb_path)
        table = db.open_table("documents")
        
        # L·∫•y t·∫•t c·∫£ records
        df = table.to_pandas()
        
        # L·ªçc records cho file c·ª• th·ªÉ
        file_records = []
        for _, row in df.iterrows():
            metadata = row.get('metadata', {})
            if metadata.get('file_name') == file_name:
                file_records.append(row)
        
        if not file_records:
            print(f"‚ùå No records found for file: {file_name}")
            return
        
        print(f"üìÑ Found {len(file_records)} chunks for file: {file_name}")
        
        # S·∫Øp x·∫øp theo chunk_index
        file_records.sort(key=lambda x: x.get('metadata', {}).get('chunk_index', 0))
        
        for i, record in enumerate(file_records):
            metadata = record.get('metadata', {})
            chunk_index = metadata.get('chunk_index', 'N/A')
            total_chunks = metadata.get('total_chunks', 'N/A')
            chunk_length = metadata.get('chunk_length', 'N/A')
            
            print(f"\nüìù Chunk {chunk_index}/{total_chunks} (Length: {chunk_length} chars):")
            print(f"   ID: {record.get('id', 'N/A')}")
            
            # Hi·ªÉn th·ªã to√†n b·ªô text
            text = record.get('text', '')
            if text:
                print(f"   Content:")
                print(f"   {text}")
            
            print(f"   {'-'*50}")
        
        return True
        
    except Exception as e:
        print(f"‚ùå Error: {e}")
        import traceback
        traceback.print_exc()
        return False

def main():
    """Main function"""
    print("üöÄ Vector Database Records Viewer")
    print("=" * 50)
    
    # Hi·ªÉn th·ªã t·∫•t c·∫£ records
    show_all_vector_records()
    
    # Hi·ªÉn th·ªã records c·ªßa file c·ª• th·ªÉ (n·∫øu c√≥)
    print(f"\n{'='*60}")
    print("üìÑ DETAILED FILE VIEW")
    print(f"{'='*60}")
    
    # T√¨m file ƒë·∫ßu ti√™n ƒë·ªÉ hi·ªÉn th·ªã chi ti·∫øt
    try:
        import lancedb
        appdata_path = os.path.join(os.getcwd(), "appdata")
        kb_dirs = [d for d in os.listdir(appdata_path) 
                  if os.path.isdir(os.path.join(appdata_path, d))]
        
        if kb_dirs:
            kb_id = kb_dirs[0]
            kb_path = os.path.join(appdata_path, kb_id)
            lancedb_path = os.path.join(kb_path, "lancedb")
            
            if os.path.exists(lancedb_path):
                db = lancedb.connect(lancedb_path)
                table = db.open_table("documents")
                df = table.to_pandas()
                
                # T√¨m file ƒë·∫ßu ti√™n
                for _, row in df.iterrows():
                    metadata = row.get('metadata', {})
                    file_name = metadata.get('file_name', '')
                    if file_name:
                        show_specific_file_records(kb_id, file_name)
                        break
    
    except Exception as e:
        print(f"‚ö†Ô∏è  Detailed view failed: {e}")
    
    print("\nüéâ Script completed!")

if __name__ == "__main__":
    main() 